{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn import datasets \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FLDA 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.02127659574468\n",
      "91.30434782608695\n",
      "87.5\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"StandardizedValues.xlsx - Sheet1.csv\")\n",
    "data['diagnosis'] = data['diagnosis'].replace({\"B\": 0, \"M\": 1})\n",
    "\n",
    "X = data.iloc[:, 2:].values\n",
    "y = data.iloc[:, 1].values\n",
    "\n",
    "np.random.seed(90)\n",
    "indices = np.random.permutation(len(X))\n",
    "train_size = int(0.67 * len(X))\n",
    "train_indices = indices[:train_size]\n",
    "test_indices = indices[train_size:]\n",
    "X_train = X[train_indices]\n",
    "y_train = y[train_indices]\n",
    "X_test = X[test_indices]\n",
    "y_test = y[test_indices]\n",
    "pca = PCA(n_components=1)\n",
    "X_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.fit_transform(X_test)\n",
    "class_1 = []\n",
    "class_2 = []\n",
    "\n",
    "for i in range(X_train.shape[0]):\n",
    "    if(y_train[i] == 1):\n",
    "        class_1.append(X_pca[i])\n",
    "    else:\n",
    "        class_2.append(X_pca[i])            \n",
    "mean_1 = np.mean(class_1)\n",
    "mean_2 = np.mean(class_2)\n",
    "\n",
    "std_1 =np.std(class_1)\n",
    "std_2 = np.std(class_2) \n",
    "\n",
    "def normal_distr(x,mean,std):\n",
    "    f = (np.exp(-(np.square(x-mean))/2*np.square(std)))/(std*np.sqrt(2*np.pi))\n",
    "f1 = normal_distr(class_1,mean_1,std_1)\n",
    "f2 = normal_distr(class_2,mean_2,std_2)\n",
    "\n",
    "s_1 = 0\n",
    "for i in range(len(class_1)):\n",
    "    s_1 = s_1 + (class_1[i] - mean_1)*np.transpose(class_1[i] - mean_1)\n",
    "\n",
    "s_1 = s_1/len(class_1)\n",
    "\n",
    "\n",
    "s_2 = 0\n",
    "for i in range(len(class_2)):\n",
    "    s_2 = s_2 + (class_2[i] - mean_2)*np.transpose(class_2[i] - mean_2)\n",
    "\n",
    "s_2 = s_2/len(class_2)\n",
    "\n",
    "s_w = s_1+s_2\n",
    "w = (mean_1 - mean_2)/s_w\n",
    "\n",
    "d = (mean_2*(std_1*np.sqrt(np.log(std_2)))/(std_2*np.sqrt(np.log(std_1)))+mean_1)/(1+((std_1*np.sqrt(np.log(std_2)))/(std_2*np.sqrt(np.log(std_1)))))\n",
    "\n",
    "\n",
    "beta = np.transpose(w)*d\n",
    "\n",
    "def checkAccuracy():\n",
    "    count = 0\n",
    "    for i in range(X_test.shape[0]):\n",
    "\n",
    "        if(np.transpose(w)*X_test_pca[i] >= beta):\n",
    "            y_pred = 1\n",
    "        else:\n",
    "            y_pred = 0\n",
    "        \n",
    "        if(y_pred == y_test[i]):\n",
    "            count += 1\n",
    "    accuracy = count*100\n",
    "    accuracy = accuracy/X_test.shape[0]\n",
    "    return accuracy\n",
    "\n",
    "def checkprecision():\n",
    "    true_positives = 0\n",
    "    total_positives = 0\n",
    "    for i in range(X_test.shape[0]):\n",
    "        if(np.transpose(w)*X_test_pca[i] >= beta):\n",
    "            total_positives += 1\n",
    "            if(y_test[i] == 1):\n",
    "                true_positives += 1\n",
    "    precision = true_positives/total_positives\n",
    "    return precision*100 \n",
    "\n",
    "def checkrecall():\n",
    "    true_positives = 0\n",
    "    false_negatives = 0\n",
    "    for i in range(X_test.shape[0]):\n",
    "        if(np.transpose(w)*X_test_pca[i] >= beta):\n",
    "            if(y_test[i] == 1):\n",
    "                true_positives += 1\n",
    "        else:\n",
    "            if(y_test[i] == 1):\n",
    "                false_negatives += 1\n",
    "\n",
    "    recall = true_positives/(true_positives + false_negatives)\n",
    "    return recall*100                    \n",
    "\n",
    "\n",
    "accuracy = checkAccuracy()\n",
    "precision = checkprecision()\n",
    "recall = checkrecall()\n",
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FLDA 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.95744680851064\n",
      "92.64705882352942\n",
      "84.0\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"StandardizedValues.xlsx - Sheet1.csv\")\n",
    "data['diagnosis'] = data['diagnosis'].replace({\"B\": 0, \"M\": 1})\n",
    "\n",
    "X = data.iloc[:, 2:]\n",
    "X = X.sample(frac = 1, axis = 1,random_state = 12)\n",
    "X = X.iloc[:,:].values\n",
    "y = data.iloc[:, 1].values\n",
    "\n",
    "np.random.seed(245)\n",
    "indices = np.random.permutation(len(X))\n",
    "train_size = int(0.67 * len(X))\n",
    "train_indices = indices[:train_size]\n",
    "test_indices = indices[train_size:]\n",
    "X_train = X[train_indices]\n",
    "y_train = y[train_indices]\n",
    "X_test = X[test_indices]\n",
    "y_test = y[test_indices]\n",
    "pca = PCA(n_components=1)\n",
    "X_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.fit_transform(X_test)\n",
    "class_1 = []\n",
    "class_2 = []\n",
    "\n",
    "for i in range(X_train.shape[0]):\n",
    "    if(y_train[i] == 1):\n",
    "        class_1.append(X_pca[i])\n",
    "    else:\n",
    "        class_2.append(X_pca[i])\n",
    "mean_1 = np.mean(class_1)\n",
    "mean_2 = np.mean(class_2)\n",
    "\n",
    "std_1 = np.std(class_1)\n",
    "std_2 = np.std(class_2)\n",
    "\n",
    "\n",
    "def normal_distr(x, mean, std):\n",
    "    f = (np.exp(-(np.square(x-mean))/2*np.square(std)))/(std*np.sqrt(2*np.pi))\n",
    "\n",
    "\n",
    "f1 = normal_distr(class_1, mean_1, std_1)\n",
    "f2 = normal_distr(class_2, mean_2, std_2)\n",
    "\n",
    "s_1 = 0\n",
    "for i in range(len(class_1)):\n",
    "    s_1 = s_1 + (class_1[i] - mean_1)*np.transpose(class_1[i] - mean_1)\n",
    "\n",
    "s_1 = s_1/len(class_1)\n",
    "\n",
    "\n",
    "s_2 = 0\n",
    "for i in range(len(class_2)):\n",
    "    s_2 = s_2 + (class_2[i] - mean_2)*np.transpose(class_2[i] - mean_2)\n",
    "\n",
    "s_2 = s_2/len(class_2)\n",
    "\n",
    "s_w = s_1+s_2\n",
    "w = (mean_1 - mean_2)/s_w\n",
    "\n",
    "d = (mean_2*(std_1*np.sqrt(np.log(std_2)))/(std_2*np.sqrt(np.log(std_1))) +\n",
    "     mean_1)/(1+((std_1*np.sqrt(np.log(std_2)))/(std_2*np.sqrt(np.log(std_1)))))\n",
    "\n",
    "\n",
    "beta = np.transpose(w)*d\n",
    "\n",
    "\n",
    "def checkAccuracy():\n",
    "    count = 0\n",
    "    for i in range(X_test.shape[0]):\n",
    "\n",
    "        if(np.transpose(w)*X_test_pca[i] >= beta):\n",
    "            y_pred = 1\n",
    "        else:\n",
    "            y_pred = 0\n",
    "\n",
    "        if(y_pred == y_test[i]):\n",
    "            count += 1\n",
    "    accuracy = count*100\n",
    "    accuracy = accuracy/X_test.shape[0]\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def checkprecision():\n",
    "    true_positives = 0\n",
    "    total_positives = 0\n",
    "    for i in range(X_test.shape[0]):\n",
    "        if(np.transpose(w)*X_test_pca[i] >= beta):\n",
    "            total_positives += 1\n",
    "            if(y_test[i] == 1):\n",
    "                true_positives += 1\n",
    "    precision = true_positives/total_positives\n",
    "    return precision*100\n",
    "\n",
    "\n",
    "def checkrecall():\n",
    "    true_positives = 0\n",
    "    false_negatives = 0\n",
    "    for i in range(X_test.shape[0]):\n",
    "        if(np.transpose(w)*X_test_pca[i] >= beta):\n",
    "            if(y_test[i] == 1):\n",
    "                true_positives += 1\n",
    "        else:\n",
    "            if(y_test[i] == 1):\n",
    "                false_negatives += 1\n",
    "\n",
    "    recall = true_positives/(true_positives + false_negatives)\n",
    "    return recall*100\n",
    "\n",
    "\n",
    "accuracy = checkAccuracy()\n",
    "precision = checkprecision()\n",
    "recall = checkrecall()\n",
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLDA1</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>FLDA2</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>State_Value</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>Precision</td>\n",
       "      <td>Recall</td>\n",
       "      <td>State_Value</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>Precision</td>\n",
       "      <td>Recall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2345</td>\n",
       "      <td>95.74</td>\n",
       "      <td>98.46</td>\n",
       "      <td>90.14</td>\n",
       "      <td>2345</td>\n",
       "      <td>95.74</td>\n",
       "      <td>98.46</td>\n",
       "      <td>90.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245</td>\n",
       "      <td>90.95</td>\n",
       "      <td>92.64</td>\n",
       "      <td>84</td>\n",
       "      <td>245</td>\n",
       "      <td>90.95</td>\n",
       "      <td>92.64</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>91.48</td>\n",
       "      <td>84.72</td>\n",
       "      <td>92.42</td>\n",
       "      <td>24</td>\n",
       "      <td>91.48</td>\n",
       "      <td>84.72</td>\n",
       "      <td>92.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>89.36</td>\n",
       "      <td>94.02</td>\n",
       "      <td>79.74</td>\n",
       "      <td>4</td>\n",
       "      <td>89.36</td>\n",
       "      <td>94.02</td>\n",
       "      <td>79.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>334</td>\n",
       "      <td>93.61</td>\n",
       "      <td>90.625</td>\n",
       "      <td>90.625</td>\n",
       "      <td>334</td>\n",
       "      <td>93.61</td>\n",
       "      <td>90.625</td>\n",
       "      <td>90.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>232</td>\n",
       "      <td>93.08</td>\n",
       "      <td>94.02</td>\n",
       "      <td>87.5</td>\n",
       "      <td>232</td>\n",
       "      <td>93.08</td>\n",
       "      <td>94.02</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2212</td>\n",
       "      <td>93.08</td>\n",
       "      <td>89.18</td>\n",
       "      <td>92.95</td>\n",
       "      <td>2212</td>\n",
       "      <td>93.08</td>\n",
       "      <td>89.18</td>\n",
       "      <td>92.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>202</td>\n",
       "      <td>95.21</td>\n",
       "      <td>92.95</td>\n",
       "      <td>94.28</td>\n",
       "      <td>202</td>\n",
       "      <td>95.21</td>\n",
       "      <td>92.95</td>\n",
       "      <td>94.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42</td>\n",
       "      <td>89.89</td>\n",
       "      <td>91.3</td>\n",
       "      <td>82.89</td>\n",
       "      <td>42</td>\n",
       "      <td>89.89</td>\n",
       "      <td>91.3</td>\n",
       "      <td>82.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>90</td>\n",
       "      <td>92.02</td>\n",
       "      <td>91.3</td>\n",
       "      <td>87.5</td>\n",
       "      <td>90</td>\n",
       "      <td>92.02</td>\n",
       "      <td>91.3</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Average</td>\n",
       "      <td>92.442</td>\n",
       "      <td>91.9215</td>\n",
       "      <td>88.2045</td>\n",
       "      <td>Average</td>\n",
       "      <td>92.442</td>\n",
       "      <td>91.9215</td>\n",
       "      <td>88.2045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          FLDA1 Unnamed: 1 Unnamed: 2 Unnamed: 3        FLDA2 Unnamed: 5  \\\n",
       "0   State_Value   Accuracy  Precision     Recall  State_Value   Accuracy   \n",
       "1          2345      95.74      98.46      90.14         2345      95.74   \n",
       "2           245      90.95      92.64         84          245      90.95   \n",
       "3            24      91.48      84.72      92.42           24      91.48   \n",
       "4             4      89.36      94.02      79.74            4      89.36   \n",
       "5           334      93.61     90.625     90.625          334      93.61   \n",
       "6           232      93.08      94.02       87.5          232      93.08   \n",
       "7          2212      93.08      89.18      92.95         2212      93.08   \n",
       "8           202      95.21      92.95      94.28          202      95.21   \n",
       "9            42      89.89       91.3      82.89           42      89.89   \n",
       "10           90      92.02       91.3       87.5           90      92.02   \n",
       "11      Average     92.442    91.9215    88.2045      Average     92.442   \n",
       "\n",
       "   Unnamed: 6 Unnamed: 7  \n",
       "0   Precision     Recall  \n",
       "1       98.46      90.14  \n",
       "2       92.64         84  \n",
       "3       84.72      92.42  \n",
       "4       94.02      79.74  \n",
       "5      90.625     90.625  \n",
       "6       94.02       87.5  \n",
       "7       89.18      92.95  \n",
       "8       92.95      94.28  \n",
       "9        91.3      82.89  \n",
       "10       91.3       87.5  \n",
       "11    91.9215    88.2045  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = pd.read_excel(\"FLDA split.xlsx\")\n",
    "report\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the above table FLDA1 and FLDA2 are the same, thus showing that changing the order of the columns does not make a difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
